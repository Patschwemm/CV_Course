{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MA - INF 2201 - Computer Vision WS 22/23\n",
    "\n",
    "### Exercise Sheet 01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "DATA_DIR = '../data'\n",
    "SIM_THRESHOLD = 0.5 # similarity threshold for template matching. Can be adapted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fourier Transform \n",
    "\n",
    "In this task, we will show a useful property of the Fourier Transform, which is the convolution property. It tells us that convolution in the spatial domain corresponds to multiplication in the frequency domain. The input image that you will be operating on is orange.jpeg and celeb.jpeg.\n",
    "\n",
    "- Load the two images orange.jpeg and celeb.jpeg. Remember to convert to grayscale.\n",
    "- Create a 7 ×7 Gaussian kernel with sigma=1.\n",
    "- Blur the images by convolving the image with the Gaussian kernel directly in the spatial domain. You may use the library function (cv2.filter2D).\n",
    "- Now we are going to blur the images in the frequency domain using Fourier Transform. We multiply the kernel function and the frequency image instead of applying convolution. To get the final result, we transform back to the image space. You may use functions included in the package numpy.fft to apply the transform and its inverse.\n",
    "- Visualise the results for both images and report the mean absolute difference between the two blurring methods and the time taken by each of them.\n",
    "    \n",
    "(3 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Template Matching \n",
    "In this task, we will implement template matching using Sum Square Difference and normalized cross-correlation similarity measures. The input image is RidingBike.jpeg and the template image (what we want to find in the larger input image) is RidingBikeTemplate.jpeg\n",
    "\n",
    "- Implement Sum Square Difference.\n",
    "- Implement template matching using your implementation of Sum Square Difference.\n",
    "- Implement Normalized Cross-correlation.\n",
    "- Implement template matching using Normalized Cross-correlation.\n",
    "- Draw rectangles on the image where similarity ≥0.5 for both methods. You may experiment with other threshold values to determine the matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Template matching multi-scale \n",
    "\n",
    "In this task, we will build the Gaussian pyramid to make template matching work at different resolutions. Read the image DogGray.jpeg and the template DogTemplate.jpeg\n",
    "- Build a 5 level Gaussian pyramid by downsampling put image yourself.\n",
    "- Now create a 5 level Gaussian pyramid using cv2.pyrDown. Compare it with your implementation by printing the mean absolute difference at each level.\n",
    "- Perform template matching by using your implementation of normalized crosscorrelation . Report the time taken by this method.\n",
    "- Show the template matching using normalized cross correlation at the different Pyramid levels of both the template and input images (you can use the pyramid obtained by pyrDown).\n",
    "- As you observed, implementing template matching naively is not efficient. Now we will rely on the pyramid technique while constraining the search space in order to make it faster. Follow the procedure described in the lecture slides: search only in regions with high similarity in the previous pyramid level. Compare the times taken by this method and the naive implementation.\n",
    "- Visualise the template matching results.\n",
    "\n",
    "(6 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Pyramids for image blending \n",
    "\n",
    "In this task, we will stitch two images using pyramids. Without pyramids, blending does not look natural because of discontinuities between the pixel values. We will blend the images dog.jpeg and moon.jpeg.\n",
    "- Load the two images dog.jpeg and moon.jpeg.\n",
    "- Create the Gaussian Pyramids of the two images, and find their Laplacian Pyramids LA and LB (remember that a Laplacian Pyramid is the difference between two levels in the Gaussian Pyramid as explained in the lecture, i.e. Li = Gi −expand(Gi+1)). Set the number of levels to 5.\n",
    "- Blend the image dog.jpeg with the image moon.jpeg: create a Gaussian pyramid GR for the region of interest in the given mask mask.jpeg (first transform the mask to grayscale).\n",
    "- Combine the Laplacian pyramids using GR as weights for the blending, i.e. LSl(i,j) = GRl(i,j) ·LAl(i,j) + (1 −GRl(i,j)) ·LBl(i,j)\n",
    "- Collapse the LS pyramid to obtain the final composite image: LSl = LSl + expand(LSl+1). Apply the blending operation on the images inside task4 (the results will be funny).\n",
    "\n",
    "(6 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Edges \n",
    "\n",
    "In this task, we will detect edges in images using the derivative of a Gaussian kernel. Read the image einstein.jpeg.\n",
    "\n",
    "- Compute the weights of the derivative (in x) of a 5x5 Gaussian kernel with σ = 0.6.\n",
    "- Compute the weights of the derivative (in y) of a 5x5 Gaussian kernel with σ = 0.6.\n",
    "- To get the edges, convolve the image with the kernels computed in previous steps. You can use cv2.filter2D.\n",
    "- Compute the edge magnitude and the edge direction (you can use numpy.arctan2). Visualise the magnitude and direction.\n",
    "\n",
    "(2 Points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blur the image in the spatial domain using convolution\n",
    "def blur_im_spatial(image, kernel_size):\n",
    "    #TODO\n",
    "    pass\n",
    "    \n",
    "\n",
    "# blur the image in the frequency domain\n",
    "def blur_im_freq(image, kernel):\n",
    "    #TODO\n",
    "    pass\n",
    " \n",
    "# implement the sum square difference (SQD) similarity \n",
    "def calc_sum_square_difference(image, template):\n",
    "    pass\n",
    "       \n",
    "# implement the normalized cross correlation (NCC) similarity \n",
    "def calc_normalized_cross_correlation(image, template):\n",
    "    pass\n",
    "\n",
    "#draw rectanges on the input image in regions where the similarity is larger than SIM_THRESHOLD\n",
    "def draw_rectangles(input_im, similarity_im):\n",
    "    pass\n",
    "\n",
    "#You can choose to resize the image using the new dimensions or the scaling factor\n",
    "def pyramid_down(image, dstSize, scale_factor=None):   \n",
    "    pass\n",
    "#create a pyramid of the image using the specified pyram function pyram_method.\n",
    "#pyram_func can either be cv2.pyrDown or your own implementation\n",
    "def create_gaussian_pyramid(image, pyram_func, num_levels):\n",
    "    #in a loop, create a pyramid of downsampled blurred images using the Gaussian kernel\n",
    "    pass\n",
    "def calc_derivative_gaussian_kernel(size, sigma):\n",
    "    # TODO: implement\n",
    "    pass\n",
    "\n",
    "def create_laplacian_pyramid(image, num_levels=5):\n",
    "    #create the laplacian pyramid using the gaussian pyramid\n",
    "    gaussian_pyramid = create_gaussian_pyramid(image, cv2.pyrdown, num_levels)\n",
    "    #complete as described in the exercise sheet\n",
    "    pass\n",
    "# Given the final weighted pyramid, sum up the images at each level with the upscaled previous level\n",
    "def collapse_pyramid(laplacian_pyramid):\n",
    "    \n",
    "    final_im = laplacian_pyramid[0]\n",
    "    for l in range(1, len(laplacian_pyramid)):\n",
    "        #TODO complete code \n",
    "        pass\n",
    "    return final_im\n",
    "#Fourier Transform\n",
    "\n",
    "def task1(input_im_file):\n",
    "    full_path = os.path.join(DATA_DIR, input_im_file)\n",
    "    image = cv2.imread(full_path, cv2.IMREAD_GRAYSCALE)\n",
    "    kernel_siZe = 7\n",
    "    kernel = None  # TODO: create kernel\n",
    "    # time the blurring of the different methods\n",
    "    start_time = time.time()\n",
    "    conv_result = blur_im_spatial(image, kernel_siZe) \n",
    "    end_time = time.time()\n",
    "    print('time taken to apply blur in the spatial domain', end_time-start_time)\n",
    "    # measure the timing here too\n",
    "    fft_result = blur_im_freq(image, kernel)\n",
    "\n",
    "    # TODO: compare results in terms of run time and mean square difference\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Template matching using single-scale\n",
    "def task2(input_im_file, template_im_file):\n",
    "    full_path_im = os.path.join(DATA_DIR, input_im_file)\n",
    "    full_path_template = os.path.join(DATA_DIR, template_im_file)\n",
    "    in_im = cv2.imread(full_path_im, cv2.IMREAD_GRAYSCALE)\n",
    "    template = cv2.imread(template_im_file, cv2.IMREAD_GRAYSCALE)\n",
    "    result_sqd = calc_sum_square_difference(in_im, template)\n",
    "    result_ncc = calc_normalized_cross_correlation(in_im, template)\n",
    "\n",
    "    #draw rectanges at matching regions\n",
    "    vis_sqd = draw_rectangles(in_im, result_sqd)\n",
    "    vis_ncc = draw_rectangles(in_im, result_ncc)\n",
    "    \n",
    "\n",
    "\n",
    "def task3(input_im_file, template_im_file):\n",
    "    pass\n",
    "    # TODO: calculate the time needed for template matching with the pyramid\n",
    "\n",
    "    # TODO: show the template matching results using the pyramid\n",
    "\n",
    "\n",
    "\n",
    "#Image blending\n",
    "def task4(input_im_file1, input_im_file2, interest_region_file, num_pyr_levels=5):\n",
    "    #TODO you can use the steps described in the exercise sheet to help guide you through the solution\n",
    "    result = None\n",
    "    return result\n",
    "\n",
    "def task5(input_im, kernel_size=5, sigma=0.5):\n",
    "    image = cv2.imread(\"../data/einstein.jpeg\", 0)\n",
    "\n",
    "    kernel_x, kernel_y = calc_derivative_gaussian_kernel(kernel_size, sigma)\n",
    "\n",
    "    edges_x = None  # TODO: convolve with kernel_x\n",
    "    edges_y = None  # TODO: convolve with kernel_y\n",
    "\n",
    "    magnitude = None  # TODO: compute edge magnitude\n",
    "    direction = None  # TODO: compute edge direction\n",
    "\n",
    "    # TODO visualise the results\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    task1('orange.jpeg')\n",
    "    task1('celeb.jpeg')\n",
    "    task2('RidingBike.jpeg', 'RidingBikeTemplate.jpeg')\n",
    "    task3('DogGray.jpeg', 'DogTemplate.jpeg')\n",
    "    task4('dog.jpeg', 'moon.jpeg', 'mask.jpeg')\n",
    "    # just for fun, blend these these images as well\n",
    "    for i in range[1,2,10]:\n",
    "        ind = str(i).zfill(2)\n",
    "        blended_im = task4('task4_extra/source_%s.jpg'%ind, 'task4/target_%s.jpg'%ind, 'task4/mask_%s.jpg'%ind)\n",
    "        #visualise the blended image\n",
    "\n",
    "    task5('einstein.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MA - INF 2201 - Computer Vision WS 22/23\n",
    "\n",
    "### Exercise Sheet 01\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
